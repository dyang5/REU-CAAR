## Week 7

### <u>Day 43 (July 17th)</u>

Week 7, Day 1

 - 8:30 - 9:00 AM: Wow. It's week 7 already, which is crazy. Time is dwindling -- I hope we get some cool research results to present in just under three weeks. Instead of getting out for my Monday morning swim, I played it safe and waited for AG, the grad lead for REU-CAAR, to bring all the isolating students COVID Test Kits (which is quite nice of him). I tested Negative and so that meant I could finally get back to work at IRB. I broughout out my mask just to be safe as well.

 - 10:00 AM - 12:00 PM: To start off the research week, I wanted to work on testing the results from the generated images (from our diffusion models) on the DeepFace classifier. After some experimentation with prompting and comparing the results to work from my other group members, I generated 15 images for each of the four types of prompts (portrait/group images of doctors/firefighters) and proceeded to hand-label the portrait images. I then used the image to classification pipeline that I had written from previous weeks, modified some of the code, and ran it on the generated images. To analyze the results, I would need to hand-label the images (since they are generated and are not part of a labeled dataset). After some discussion with my group, I ended up doing this for the portrait images before heading to lunch.

 - 12:00 - 1:30 PM: We had another one of our weekly Monday REU lunch talks. Today Bill gave a talk on [The Hat Problem](https://www.cs.umd.edu/~gasarch/REU/hatstalk.pdf). I had seen this problem before but did not remember the strategy (and I also had not seen the many extensions proposed by Bill); overall, I found the talk quite enjoyable and it was great to think mathematically/problem-solve for the first time in a while. I definitely want to ask Bill whether I can present a version of this to professors at Swarthmore, or even present it as part of the IMC (Interactive Math Colloquium) Club I run, since I very much enjoyed this talk!

- 1:30 - 4:00 PM: I quite enjoyed Bill's Hat Talk so I spent some time afterwards discussing the proofs (especially the infinite hat, 2 colors and infinite hat, at most 1 error cases) with AF and SS (XG, our final group member, is going to be working remotely this week). We talked a bit about the [Axiom of Choice](https://en.wikipedia.org/wiki/Axiom_of_choice), our thoughts on it, as well as some resulting paradoxes including Banachâ€“Tarski (the Axiom of Choice is used in one of the proofs discussed by Bill). Afterwards, I ended up discussing the general research plan (what everyone was working on, potential limitations of our research and what we can do to address them, and what we can do next to get a solid research project before the REU ends) with my group members AF and SS. I think this was really productive -- at times, I feel like I've only been working on a small part of the pipeline, but it's important to realize that the general fairness process we are trying to build relies on many different small but essential parts. AF and I also tried to reason through mathematical foundation behind a Latent Diffusion Model paper SS was trying to read through, to some success. I didn't get too much done outside of this group discussion, but I feel like having these sorts of discussions is really necessary to get everyone aligned and on the same page and to build a solid working dynamic, so I was quite happy with that. 

After research, I ended up relaxing a bit before heading out to "play badminton" with ZF, AG, and SS. It turns out there were only 3 badminton racquets, and since I didn't want them to have to rotate, I ended up playing Racquetball on my own for 30ish minutes. Afterwards, I waited around and watched them and others play badminton. This ended up taking much longer than anticipated, which I was okay with since I mainly was on my phone after a while, but it meant that we had to jog to CFA before it closed at 7. Obviously, then, since we ordered right before closing, the food wasn't as good as normal. Oh well.

Outside of research, I've been waiting for my monitor to arrive (it was supposed to arrive yesterday but the delivery didn't go through), and it hasn't arrived yet today, either, which kind of sucks. I'm really looking forward to a better setup to hopefully allow me to be more productive and work easier in my room. I've also been waiting to hear from the [Young Mathematicians Conference](https://ymc.osu.edu/), a math conference I applied to using my work from last year, so fingers crossed on that front! 


### <u>Day 44 (July 18th)</u>

Week 7, Day 2

 - 8:30 - 9:00 AM: I had planned to exercise outside yesterday (swim or run) and in the morning today, but we hit another wave of bad air quality (I think this is the third one in this REU program alone, with 130+ AQI, meaning the Air Quality is unhealthy for outdoor activity). When I woke up at 6:30 AM to check on the AQI, it was still Unhealthy, so I set my alarms for 9 to get an extra hour of sleep.

 - 10:00 AM - 12:00 PM: Over the last few days, I've been focused on trying to get good diffusion model output as well as trying to test the DeepFace classifier on the generated output. For the latter part, I have everything I need to do this (I would need to write a bit more code to do so but it wouldn't take too long), but I have been putting it off. My reasoning for this is twofold: many of the generated group images have terrible image quality (faces are deformed), making labeling and comparing to the results from the classifier difficult/not useful. Furthermore, even for the single images (one person in an image), the hand-labeling of a person's race is very subjective and thus it's difficult to accurately analyze the classifier. As a result, I've moved away from this and have thought more about how we can get fair image generation. One of our current projects, led by AF, is Domain Translation, which involves masking a certain part of an image (e.g. one person) and using a Blended Latent Diffusion model to "translate" that person's gender or race. For example, one can mask a man and say "change this person to a woman." Ideally, this person would look very similar characteristic wise as to what the original person is wearing, since the model tries to "blend" the result into the rest of the image. Through some initial experiments, this has been unsuccessful/difficult. As a result, I've been looking into some work that follows a [Semantic Guidance](https://arxiv.org/pdf/2301.12247.pdf) paper, where given an image and a concept, the concept is added/suppressed in the image while preserving the other characteristics of an image.

 - 1:00 - 4:00 PM: In the morning, I read a bit about the paper and the general process before starting to implement the code from the [Semantic Guidance Colab](https://colab.research.google.com/github/ml-research/semantic-image-editing/blob/main/examples/SemanticGuidance.ipynb#scrollTo=4e6e6724) locally. I got this working and started looking at generating group images and how guidance on gender/race would affect the image. Tomorrow, I want to try to combine our existing domain translation approach (where a certain part of the image is masked) and the Semantic Guidance approach. My (maybe optimistic) hope is to be able to mask a certain part of the image, guide that part of the image, and "stitch" the resulting parts together to lead to a fair outcome, as this will preserve general background characteristics in a generated image while making the image more fair. We closed the day by talking a bit as a group, and we somehow ended up working on some math problems from China's famous Gaokao examination (which was fun) as well.

 After research, I headed to the gym to play basketball with PM, MA, AB, SS, and DS before joining AG and ZS at the pool afterwards. We mainly messed around at the pool (there was so many people and the lanes were all packed), which included teaching me and ZS attempting to teach SS how to dive into a pool as well as going on the slide/diving boards. I also briefly swam a few laps near the end, when lanes started to free up. I got home back around 8 PM, warmed up some leftover pizza, did some CodeForces, and that was that. 

 For some non-research related content, I had to cancel my monitor shipment from Amazon today, since it has not been delivered despite remaining at the Amazon facilities. This kind of sucks since I was hoping to work on a monitor for the remainder of the REU (and I will hand it off to Sherry post research for her to use in industry). On the plus side, I found out today I was accepted as a Report Presenter at this year's YMC (Young Mathematicians Conference), which I am quite happy about! I guess maybe not getting a monitor for now is a small price to pay for getting accepted into YMC. :)

