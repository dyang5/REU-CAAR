## Week 1

### <u>Day 1 (June 5th)</u>

Orientation and Introduction Day!
 - 11 AM - 12 PM: Bill Gasarch (program director) gave us a program overview and we learned about the other groups.
 My group members include SS, AF, and XG (initialed for privacy).
 - 1:30 - 4:00 PM: Met with Furong and Pan to discuss research goals for the summer. Since Furong is leaving for China in a few days, we laid out expectations for our project as well as started brainstorming ideas based on our group's interests and collective research experiences. Our preliminary ideas/thoughts include **concept-level fairness in LLMs** and **Fairness in Generative AI/Diffusion Models**.
 - 4:00 - 5:00 PM: Listened to Professor Victor Albert discuss the Quantum Error Computing Project

Socially, I ended up going to Target to get stuff for our suite, with one of program leaders and graduate students Auguste, along with SS, AZ, and AB. I then headed to the Gym to get a membership and play Raquetball with SS and AZ before heading to a late dinner with SS and AZ (after finding that the Student Union apparently closes at 4 PM).

### <u>Day 2 (June 6th)</u>

Literature Review (pt. 1)
 - 10 - 11:30 AM: We organized papers into categories, including Vision Language Models, Fairness (in Language Models), Group Fairness, and Generative Models, including GANs and Diffusion Models. After organizing our work, I spent most of the morning reading background about vision language models and the pioneer paper for GANs (Generated Adversarial Nets) to better understand the research context we hope to work on. As a group, we are hoping to work on fairness in the context of generative models such as diffusion.
 - 11:30 AM - 1:30 PM: Headed to get University of Maryland ID Cards and then lunch.
 - 1:30 - 3:00ish PM: Read more about Denoising Diffusion Probabilistic and Implicit Models (DDPM and DDIMs). These papers were a bit more dense/harder to read and understand but I found another resource to summarize major differences and similarities (my understanding is discussed below):
 
 > DDIMs are consistent-- i.e. starting with similar latent variables will yield to results with similar features -- whereas DDPMs are not, and DDIMs can run much faster than DDPMs as a series of Markov jumps (each of which can be modeled as Gaussian) can be modeled as a larger combination of Gaussians. On the other hand, DDPMs approximate the reverse diffusion process (from data to noise) and can run much slower.

 - 3:00 - 4:00 PM: We discussed a general research plan for what we want to work on this summer. I felt this discussion was fruitful -- we talked about a [Fair Diffusion Paper](https://arxiv.org/abs/2302.10893) that seems close to what we want to do, and possible extensions/limitations of that research and the scope of our work. Tomorrow, I'm hoping to continue reading this paper and another one a Grad Student shared as of 6:00 PM.

 - 4:00 - 5:00 PM: Listened to Auguste (AG, a grad student mentor for the Computational Geometry project as well as co-lead of the REU program) discuss the Computational Geometry project, including the Hilbert Metric, Voronoi Diagrams (whose dual is the Delaunay Triangulation), and the Delaunay Triangulation. I found it quite interesting how similar the project was to my Circle Packings project last summer, which you can find more about [here](https://github.com/dyang5/CirclePackingsResearch).

 After research hours, I went to Chick-Fil-A (CFA) in the Student Union with ML, DS, PM, and NL before heading to the gym with ML and DS. DS and I played tennis before heading back, and I ended up back in the dorm soon after, playing cards with AB. Socially, I'm happy with how the REU is going but I want to keep making friends/being around people outside my suite and REU group as well. Though paper reading can be montonous, I felt like the discussion about our project was fruitful and so today was overall a solid REU day.